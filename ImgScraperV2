from contextlib import nullcontext
from ctypes import sizeof
from email.errors import StartBoundaryNotFoundDefect
from types import NoneType
from urllib import request
import requests # to get image from the web
import shutil # to save it locally
import os
from os.path import basename
from bs4 import *

def chapterDownloader(mangaUrl,filePath,chNumber):
    pageFormat = 2
    folderName = "CH"
    
    if not os.path.exists(filePath):
        os.makedirs(filePath)

    folderPath = filePath + '/' + folderName + str(chNumber).zfill(3)

    if not os.path.exists(folderPath):
        os.makedirs(folderPath)

    for pageNumber in range(1,1000):
        webUrl = mangaUrl + str(chNumber) + "/" + str(pageNumber)
        print(webUrl) 
        htmlData = requests.get(webUrl,headers={'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'})
        soup = BeautifulSoup(htmlData.text, 'html.parser')
        image = soup.findAll('img')
        if image == None:
            break
        imageUrl = image.get('data-src')
        splitUrl = imageUrl.split('.')
        suffix = splitUrl[len(splitUrl) - 1] 
        imageRequest(imageUrl.strip(),folderPath + "/" + str(pageNumber).zfill(2) + "." + suffix)
        print(imageUrl.strip())

    print("Chapter " + str(chNumber) + " downloaded")


    

def multiChaptersDownloader(mangaUrl,filePath,chMin,chMax):
    return 0

def volumeDownloader(mangaUrl,filePath,volumeList,volumeNumber):
    return 0

def multiVolumesDownloader(mangaUrl,filePath,volumeList,volumeMin,volumeMax):
    return 0    


def imageRequest(webUrl,fileDestination,headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}):
    r = requests.get(webUrl, stream = True,headers=headers)
    
    if r.status_code == 200:
        r.raw.decode_content = True
        with open(fileDestination,'wb') as f:
            shutil.copyfileobj(r.raw, f)
    return r.status_code

def test(webUrl):
    r = requests.get(webUrl,headers={'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'})
    soup = BeautifulSoup(r.text, 'html.parser')
    image = soup.find('img')
    if image == None:
        print("yes")

#print(imageRequest('https://www.scan-vf.net/uploads/manga/jujutsu-kaisen/chapters/chapitre-197/05.jpg','test.jpg'))
print(chapterDownloader("https://www.scan-vf.net/my-hero-academia/chapitre-","Test",363))
#test("https://www.scan-vf.net/my-hero-academia/chapitre-363/15")
#print(imageRequest("https://www.scan-vf.net/uploads/manga/my-hero-academia/chapters/chapitre-363/01.jpg","Test/CH363/01.jpg"))